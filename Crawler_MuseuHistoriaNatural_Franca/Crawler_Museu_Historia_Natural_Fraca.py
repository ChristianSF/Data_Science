# -*- coding: utf-8 -*-
"""Teste_Crawler

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hs8DIw_vY61uT8EIE01pkc8GGpOEMals
"""

import requests
from bs4 import BeautifulSoup
import csv
import os
from datetime import date
import pandas as pd

"""#Criando pastas"""

def Cria_Diretorios():

  os.chdir("/content")
  print("Pasta atual: " + os.getcwd())

  if os.path.exists("Coletas") == True:
    print("Pasta Principal já existe")

  else:
    os.mkdir("Coletas")
    print("Pasta principal criada")

  os.chdir("Coletas")

  data_atual = "eae"

  if os.path.exists("Coleta_"+data_atual) == True:
    print("Essa pasta já existe")

  else: 
    data_atual = date.today()
    data_atual = data_atual.strftime('%d-%m-%Y')
    data_atual = str(data_atual)
    os.mkdir("Coleta_"+data_atual)
    print("Pasta secundária criada")
    os.chdir("Coleta_"+data_atual)
    os.mkdir("Imagens_400px")
    os.mkdir("Imagens_1417px")

Cria_Diretorios()

"""#Coleta dos links"""

def Coleta_Link():
  link = "https://science.mnhn.fr/institution/mnhn/collection/f/item/list?listCount=1&listIndex=1"
  url = requests.get(link)
  soup = BeautifulSoup(url.text, 'html.parser')

  palavra = []
  palavra = soup.find(class_="catalog-number").string

  print(palavra)

  #Tirando Espaços
  palavra_formatada = palavra.replace(" ", "")

  #Tirando \n
  palavra_formatada = palavra_formatada.replace("\n", "")

  #Tirando o inicio da string
  palavra_formatada = palavra_formatada.replace("MNHN-F-", "")

  #Deixando em letras minusculas
  palavra_formatada = palavra_formatada.lower()

  print(palavra_formatada)

Coleta_Link()

"""#Coleta de Informações sobre os fosséis"""

csv_file = open('Dados.csv', 'w', newline='')
csv_writer = csv.writer(csv_file)
csv_writer.writerow(['id', 'link', 'Titulo_pagina', 'foto', 'numero_catalogo', 'colecao_original','estado_colecao', 'filo', 'classe', 'ordem', 'familia', 'genero', 'especie', 'nome', 'país', 'estado_provincia', 'municipio', 'nome_coletor', 'era', 'sistema', 'series', 'estagio', 'data_coleta'])

def coleta_info(): 
  #Definindo algumas variáveis
  data_atual = date.today()
  jpg = ".jpg"

  id = "1025"

  id = int(id)

  for i in range(1):  

    #palavra_atual = palavra_formatada

    #Coleta_Link()

    id = str(id)

    print(id)

    link = 'https://science.mnhn.fr/institution/mnhn/collection/f/item/b43310?listIndex=4&listCount=381574'
    url = requests.get(link)
    soup = BeautifulSoup(url.text, 'html.parser')

    titulo_pagina = soup.title.string

    if titulo_pagina == "Apache Tomcat/8.0.30 - Rapport d''erreur":
      id = int(id)
      id += 1

    elif titulo_pagina[0] == "I":
      id = int(id)
      id += 1

    else:
      #Pegando a imagem

      imagem = soup.find_all(class_='img-carousel')

      for img in imagem:
        if img.has_attr('src'):
          foto = img['src'] 

          url_img_400 = foto
          response = requests.get(url_img_400)
          if response.status_code == 200:
            with open("Imagens_400px/Img_"+id+jpg, 'wb') as f:
              f.write(response.content)

      #for img in imagem:
        #if img.has_attr('id'):
          #foto_id = img['id'] 

          #url_img_1417 = foto_id
          #response = requests.get(url_img_1417)
          #if response.status_code == 200:
            #with open("Imagens_1417px/Img_"+id+jpg, 'wb') as f:
              #f.write(response.content)

      #Número do catálogo
      numero_catalogo = soup.find(class_='catalog-number-marked').string

      #Nome da Coleção original
      colecao_original = soup.find(class_='original-collection').a.string

      #Status da coleção
      estado_colecao = soup.find(id="occurrence-status")

      if estado_colecao is None:
        estado_colecao = "Não informado"

      else: 
        estado_colecao = soup.find(id="occurrence-status").string

      #filo
      filo = soup.find(id="phylum")

      if filo is None:
        filo = "Não informado"

      else:
        filo = soup.find(id="phylum").string

      #classe
      classe = soup.find(id="class")
      
      if classe is None: 
        classe = "Não informado"

      else:
        classe = soup.find(id="class").string

      #ordem
      ordem = soup.find(id="order").string
    
      if ordem is None:
        ordem = "Não informado"

      else:
        ordem = soup.find(id="order").string

      #familia
      familia = soup.find(id="family")

      if familia is None:
        familia = "Não informado"
      else:
        familia = soup.find(id="family").string

      #genero
      genero = soup.find(id="genus")

      if genero is None:
        genero = "Não informado"
      else:
        genero = soup.find(id="genus").string

      #especie
      especie = soup.find(id="species")

      if especie is None:
        especie = "Não informado"

      else:
        especie = soup.find(id="species").string

      #nome
      nome = soup.find(id="scientific-name").text

      #País
      pais = soup.find(id="country").text

      #Estado/Provincía
      estado_provincia = soup.find(id="stateProvince")

      if estado_provincia is None:
        estado_provincia = "Não informado"

      else: 
        estado_provincia = soup.find(id="stateProvince").string

      #Município
      municipio = soup.find(id="municipality")

      if municipio is None:
        municipio = "Não informado"

      else:
        municipio = soup.find(id="municipality").string

      #Nome coletor
      nome_coletor = soup.find(id="recordedBy")

      if nome_coletor is None:
        nome_coletor = "Não informado"

      else:
        nome_coletor = soup.find(id="recordedBy").a.text

      #Estatigrafia
      ##Era
      era = soup.find(id="earliestEraOrLowestErathem")

      if era is None:
        era = "Não informado"

      else:
        era = soup.find(id="earliestEraOrLowestErathem").string

      #Sistema
      sistema = soup.find(id="earliestPeriodOrLowestSystem")

      if sistema is None:
        sistema = "Não informado"

      else: 
        sistema = soup.find(id="earliestPeriodOrLowestSystem").string

      #series
      series = soup.find(id="earliestEpochOrLowestSeries")

      if series is None:
        series = "Não informado"

      else:
        series = series = soup.find(id="earliestEpochOrLowestSeries").string

      #Estágio
      estagio = soup.find(id="earliestAgeOrLowestStage")

      if estagio is None:
        estagio = "Não informado"
      
      else:
        estagio = soup.find(id="earliestAgeOrLowestStage").string
      
      csv_writer.writerow([id, link ,titulo_pagina, foto, numero_catalogo, 
                          colecao_original, estado_colecao, filo, classe, ordem,
                          familia, genero, especie, nome, pais, estado_provincia,
                          municipio, nome_coletor, era, sistema, series, estagio, data_atual])
      
      #Iterando o contador
      id = int(id)
      id += 1

  csv_file.close()

coleta_info()

"""#Teste células separadas"""

url = requests.get('https://science.mnhn.fr/institution/mnhn/collection/f/item/r61080?listIndex=2&listCount=2&lang=en_US')

soup = BeautifulSoup(url.text, 'html.parser')

titulo_pagina = soup.title.string
titulo_pagina

titulo_pagina[3]

estagio2 = soup.find(id="earliestAgeOrLowestStage")

if estagio2 is None:
  print("a")

else: 
  print("b")

nome_coletor = soup.find(id="recordedBy")

if nome_coletor is None:
  print("a")
else:
  print("b")

nome_coletor

"""##Foto"""

soup.find(class_='img-carousel')

#Pegando a imagem
imagem = soup.find_all(class_='img-carousel')

for img in imagem:
  if img.has_attr('id'):
    print(img['id'])
    foto = img['id']

"""##Espécimie Fóssil"""

#Número do catálogo
numero_catalogo = soup.find(class_='catalog-number-marked').string
numero_catalogo

#Nome da Coleção original
colecao_original = soup.find(class_='original-collection').a.string
colecao_original

#Status da coleção

estado_colecao = soup.find(id="occurrence-status").string
estado_colecao

"""##Tafonomia"""

filo = soup.find(id="phylum").string
filo

classe = soup.find(id="class").string
classe

ordem = soup.find(id="order").string
ordem

familia = soup.find(id="family").string
familia

genero = soup.find(id="genus").string
genero

especie = soup.find(id="species").string
especie

nome = soup.find(id="scientific-name").text
nome

"""##Origem"""

pais = soup.find(id="country").text
pais

estado_provincia = soup.find(id="stateProvince").string
estado_provincia

municipio = soup.find(id="municipality").string
municipio

nome_coletor = soup.find(id="recordedBy").a.text
nome_coletor

"""##Estatigrafia"""

era = soup.find(id="earliestEraOrLowestErathem").string
era

sistema = soup.find(id="earliestPeriodOrLowestSystem").string
sistema

series = soup.find(id="earliestEpochOrLowestSeries").string
series

estagio = soup.find(id="earliestAgeOrLowestStage").string
estagio

"""##Enviando para o csv"""

csv_file = open('teste2.csv', 'w', newline='')
csv_writer = csv.writer(csv_file)

csv_writer.writerow([id, url ,titulo_pagina, foto, numero_catalogo, colecao_original, estado_colecao, filo, classe, ordem, familia, genero, especie, nome, pais, estado_provincia, municipio, nome_coletor, era, sistema, series, estagio])

"""#Abrindo com o Pandas"""

import pandas as pd

dados = pd.read_csv("Dados.csv")

dados.head()

dados.shape

csv_file.close()

id = int(id)

id += 1

id

id = str(id)

id